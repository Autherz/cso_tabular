{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Particle():\n",
    "#     def __init__(self):\n",
    "#         self.position = np.array([(-1) ** (bool(random.getrandbits(1))) \n",
    "#                                   * random.random() * 50, \n",
    "#                                   (-1)**(bool(random.getrandbits(1)))\n",
    "#                                  * random.random()*50])\n",
    "#         self.pbest_position = self.position\n",
    "#         self.pbest_value = float('inf')\n",
    "#         self.velocity = np.array([0, 0])\n",
    "    \n",
    "#     def __str__(self):\n",
    "#         print(\"I am at \", self.position, \" meu pbest is \", self.pbest_position)\n",
    "    \n",
    "#     def move(self):\n",
    "#         self.position = self.position + self.velocity\n",
    "    \n",
    "# class Space():\n",
    "    \n",
    "#     def __init__(self, target, target_error, n_particles):\n",
    "#         self.target = target\n",
    "#         self.target_error = target_error\n",
    "#         self.n_particles = n_particles\n",
    "#         self.particles = []\n",
    "        \n",
    "#         self.gbest_value = float('inf')\n",
    "#         self.gbest_position = np.array([random.random() * 50, random.random() * 50])\n",
    "    \n",
    "#     def print_particles(self):\n",
    "#         for particle in self.particles:\n",
    "#             particle.__str__()\n",
    "    \n",
    "#     def fitness(self, particle):\n",
    "#         return particle.position[0] ** 2 + particle.position[1] ** 2 + 1\n",
    "    \n",
    "#     def set_pbest(self):\n",
    "#         for particle in self.particles:\n",
    "#             fitness_cadidate = self.fitness(particle)\n",
    "            \n",
    "#             if(particle.pbest_value > fitness_cadidate):\n",
    "#                 particle.pbest_value = fitness_cadidate\n",
    "#                 particle.pbest_position = particle.position\n",
    "    \n",
    "#     def set_gbest(self):\n",
    "#         for particle in self.particles:\n",
    "#             best_fitness_cadidate = self.fitness(particle)\n",
    "#             if(self.gbest_value > best_finess_cadidate):\n",
    "#                 self.gbest_value = best_finess_cadidate\n",
    "#                 self.gbest_position = particle.position\n",
    "                \n",
    "#     def move_particles(self):\n",
    "#         for particle in self.particles:\n",
    "#             global W\n",
    "#             new_velocity = (W*particle.velocity) + (c1*random.random()) * (particle.pbest_position - particle.position) + \\\n",
    "#                             (random.random()*c2) * (self.gbest_position - particle.position)\n",
    "#             particle.velocity = new_velocity\n",
    "#             particle.move()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2689414213699951"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "def sigmoid_function(particle):\n",
    "    return 1 / (1+math.exp(-particle))\n",
    "\n",
    "particle = [1, 0, 0, 0, 1, 0, 1, 0]\n",
    "sigmoid = sigmoid_function(-1)\n",
    "sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(particle_position, X, y, x_test, y_test):\n",
    "    particle_position = particle_position.tolist()\n",
    "    \n",
    "    if(particle_position.count(0) != len(particle_position)):\n",
    "        # get index with value 0\n",
    "        cols = [index for index in range(\n",
    "            len(particle_position)) if particle_position[index] == 0]\n",
    "\n",
    "        # get features subset\n",
    "        X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "        x_test_parsed = x_test.drop(X.columns[cols], axis=1)\n",
    "        X_subset = pd.get_dummies(X_parsed)\n",
    "        x_test_subset = pd.get_dummies(x_test_parsed)\n",
    "        \n",
    "        # apply classification algorithm\n",
    "        clf = DecisionTreeClassifier().fit(X_subset, y)\n",
    "        y_pred = clf.predict(x_test_subset)\n",
    "        score = f1_score(y_pred, y_test, average='macro')\n",
    "        print(score)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        # print(particle_position , \" -> \", mse)\n",
    "        # return (avg(cross_val_score(clf, X_subset, y, cv=5)),)\n",
    "        # return particle_position[0]**2 + particle_position[1]**2 + 1\n",
    "        return np.sqrt(mse)\n",
    "    else:\n",
    "        return(1)\n",
    "    \n",
    "    #return particle_position[0]**2 + particle_position[1]**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris():\n",
    "    df = pd.read_csv('datasets/iris.csv',)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.iloc[:, -1])\n",
    "    y = le.transform(df.iloc[:, -1]) # label\n",
    "    X = df.drop([df.columns[0], 'Species'], axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine():\n",
    "    df_red = pd.read_csv('datasets/winequality_red.csv')\n",
    "    df_white = pd.read_csv('datasets/winequality_white.csv')\n",
    "    df_red['color'] = \"R\"\n",
    "    df_white['color'] = \"W\"\n",
    "    print(df_red.size)\n",
    "    print(df_white.size)\n",
    "    df = pd.concat([df_red, df_white])\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.iloc[:, -1])\n",
    "    y = le.transform(df.iloc[:, -1]) # label\n",
    "    X = df.drop([df.columns[0], 'color'], axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic():\n",
    "    train = pd.read_csv('datasets/titanic_train.csv')\n",
    "    test = pd.read_csv('datasets/titanic_test.csv')\n",
    "    \n",
    "    full_data = [train, test]\n",
    "    \n",
    "    PassengerId = test['PassengerId']\n",
    "    # Some features of my own that I have added in\n",
    "    # Gives the length of the name\n",
    "    train['Name_length'] = train['Name'].apply(len)\n",
    "    test['Name_length'] = test['Name'].apply(len)\n",
    "    # Feature that tells whether a passenger had a cabin on the Titanic\n",
    "    train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "    # Feature engineering steps taken from Sina\n",
    "    # Create new feature FamilySize as a combination of SibSp and Parch\n",
    "    for dataset in full_data:\n",
    "        dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    # Create new feature IsAlone from FamilySize\n",
    "    for dataset in full_data:\n",
    "        dataset['IsAlone'] = 0\n",
    "        dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    # Remove all NULLS in the Embarked column\n",
    "    for dataset in full_data:\n",
    "        dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    # Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "    for dataset in full_data:\n",
    "        dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "    train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "    # Create a New feature CategoricalAge\n",
    "    for dataset in full_data:\n",
    "        age_avg = dataset['Age'].mean()\n",
    "        age_std = dataset['Age'].std()\n",
    "        age_null_count = dataset['Age'].isnull().sum()\n",
    "        age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "        dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "        dataset['Age'] = dataset['Age'].astype(int)\n",
    "    train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "    # Define function to extract titles from passenger names\n",
    "    def get_title(name):\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        # If the title exists, extract and return it.\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "    # Create a new feature Title, containing the titles of passenger names\n",
    "    for dataset in full_data:\n",
    "        dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    # Group all non-common titles into one single grouping \"Rare\"\n",
    "    for dataset in full_data:\n",
    "        dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "        dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    for dataset in full_data:\n",
    "        # Mapping Sex\n",
    "        dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "        # Mapping titles\n",
    "        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "        dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "        # Mapping Embarked\n",
    "        dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "        # Mapping Fare\n",
    "        dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "        dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "        dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "        dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "        dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "        # Mapping Age\n",
    "        dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "        dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "        dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;\n",
    "    # Feature selection\n",
    "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "    train = train.drop(drop_elements, axis = 1)\n",
    "    train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "    test  = test.drop(drop_elements, axis = 1)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train.iloc[:, 1])\n",
    "    y = le.transform(train.iloc[:, 1])\n",
    "    X = train.drop([train.columns[0], 'Survived'], axis=1)\n",
    "  \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20787\n",
      "63674\n",
      "0.9783248081841431\n",
      "All feature error :  0.1271222307943787\n",
      "update from : inf  to  1\n",
      "[0 0 0 0 0 0 0 0 0 0 0]\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "Don't change!!!\n",
      "------->  0 <--------\n",
      "0.9522715659033567\n",
      "update from : 1  to  0.18814417367671946\n",
      "[1 1 0 1 0 0 1 1 1 0 0]\n",
      "Don't change!!!\n",
      "0.979862547747999\n",
      "update from : 0.18814417367671946  to  0.1224980467213984\n",
      "[1 0 1 1 1 1 1 0 1 0 1]\n",
      "Don't change!!!\n",
      "0.9767644781707681\n",
      "0.9622279360016883\n",
      "0.9345637262032838\n",
      "0.9747254302249727\n",
      "0.9605279845333242\n",
      "0.9384907735464245\n",
      "0.846335983602865\n",
      "0.9265441496625126\n",
      "0.9667976110632046\n",
      "0.945783782398459\n",
      "0.9717186166071639\n",
      "0.953259804430917\n",
      "0.9343556994991253\n",
      "0.937325778442893\n",
      "0.9752797553656437\n",
      "0.9776330549732064\n",
      "0.9747778097962733\n",
      "0.8456128660679925\n",
      "0.975757045317831\n",
      "0.9195455189083858\n",
      "0.9012062010086991\n",
      "0.9647596031138337\n",
      "0.9505846563361536\n",
      "0.9512081241268132\n",
      "0.9281237957567032\n",
      "0.9802443442679354\n",
      "update from : 0.1224980467213984  to  0.12091736054029124\n",
      "[0 0 1 0 0 1 1 1 1 0 1]\n",
      "Don't change!!!\n",
      "0.9075856347042788\n",
      "0.9736664085935371\n",
      "------->  1 <--------\n",
      "0.9746726714602927\n",
      "0.9752025112347222\n",
      "0.9786279350512576\n",
      "0.9756041250883493\n",
      "0.9601582338647945\n",
      "0.9823051131466725\n",
      "update from : 0.12091736054029124  to  0.11437637255098745\n",
      "[0 1 1 0 0 1 1 0 1 1 0]\n",
      "Don't change!!!\n",
      "0.9617705381535301\n",
      "0.9597879126895337\n",
      "0.9813039217723668\n",
      "0.9316104728864145\n",
      "0.7640980551871641\n",
      "0.9767644781707681\n",
      "0.9541882667728229\n",
      "0.9765927319487043\n",
      "0.9472954639592963\n",
      "0.9829249573706262\n",
      "update from : 0.11437637255098745  to  0.11268181409346918\n",
      "[1 0 1 1 0 1 0 0 1 1 0]\n",
      "Don't change!!!\n",
      "0.979883505689264\n",
      "0.96123368080657\n",
      "0.9400100605383344\n",
      "0.9792485069145029\n",
      "0.9696617887240485\n",
      "0.9745390932309708\n",
      "0.9486129443350335\n",
      "0.96123368080657\n",
      "0.965903452947743\n",
      "0.9731079581723567\n",
      "0.9494906753202675\n",
      "0.9778662412497907\n",
      "0.940072735483912\n",
      "0.946550043978713\n",
      "------->  2 <--------\n",
      "0.9319310451685134\n",
      "0.980895237607076\n",
      "0.9812841156222546\n",
      "0.9755783139154208\n",
      "0.951130746346998\n",
      "0.9797779547167116\n",
      "0.9666919776878542\n",
      "0.9767158509599448\n",
      "0.9768127555915151\n",
      "0.9818710929380269\n",
      "0.979862547747999\n",
      "0.9631855073047826\n",
      "0.8302993172248165\n",
      "0.9455560319296081\n",
      "0.975254100116636\n",
      "0.9813039217723668\n",
      "0.9753053183672435\n",
      "0.9573208214253563\n",
      "0.9591661437829206\n",
      "0.9444604549883695\n",
      "0.9761859422282918\n",
      "0.9737483326451007\n",
      "0.9579560453650275\n",
      "0.9752283522104495\n",
      "0.979904388179313\n",
      "0.9535047085651042\n",
      "0.9606962465595983\n",
      "0.979904388179313\n",
      "0.9614875992015814\n",
      "0.9859853484550092\n",
      "update from : 0.11268181409346918  to  0.10192453583035047\n",
      "[1 1 1 1 0 1 0 0 1 0 0]\n",
      "Don't change!!!\n",
      "------->  3 <--------\n",
      "0.9710695964405092\n",
      "0.9758072869474457\n",
      "0.9788957184009632\n",
      "0.9333839553757086\n",
      "0.977221336044453\n",
      "0.9756809998914979\n",
      "0.943112988441524\n",
      "0.9784144408375572\n",
      "0.9781183347499078\n",
      "0.9788518905964056\n",
      "0.9627258226181958\n",
      "0.9777971680298451\n",
      "0.9424449480398716\n",
      "0.9834510511829888\n",
      "0.9548892835988182\n",
      "0.9768367640986183\n",
      "0.9778432997874478\n",
      "0.9570085918244637\n",
      "0.980895237607076\n",
      "0.8093480505378909\n",
      "0.9626866385911179\n",
      "0.9778202755035474\n",
      "0.9596196411697122\n",
      "0.9767644781707681\n",
      "0.9788298578889221\n",
      "0.9292216915972689\n",
      "0.9314938615526857\n",
      "0.9773397757518401\n",
      "0.9722184831631488\n",
      "0.9824167418819256\n",
      "------->  4 <--------\n",
      "0.9762851792784428\n",
      "0.9783697859449383\n",
      "0.9762357399332755\n",
      "0.9518794253172194\n",
      "0.977386557067917\n",
      "0.9685029592981522\n",
      "0.9762108860755463\n",
      "0.9757064399721174\n",
      "0.9803275174929367\n",
      "0.9643435313486075\n",
      "0.9762851792784428\n",
      "0.9798415140194165\n",
      "0.8769825031050802\n",
      "0.9849789055772222\n",
      "0.9814018834260416\n",
      "0.9788298578889221\n",
      "0.9569616480095384\n",
      "0.9742497451725456\n",
      "0.980895237607076\n",
      "0.9798415140194165\n",
      "0.9747516671996497\n",
      "0.9621484793415371\n",
      "0.9536014377186927\n",
      "0.9237724572069574\n",
      "0.9676984941546258\n",
      "0.9592935042606598\n",
      "0.9616097377918305\n",
      "0.9751244257274119\n",
      "0.9792265797470743\n",
      "0.9560648382474461\n",
      "------->  5 <--------\n",
      "0.9599049690686661\n",
      "0.9793354260289351\n",
      "0.9767644781707681\n",
      "0.9756809998914979\n",
      "0.9835027334110907\n",
      "0.978302197330382\n",
      "0.9623679959843752\n",
      "0.9736389029484678\n",
      "0.8393184098766842\n",
      "0.9682364040673848\n",
      "0.9798204041652855\n",
      "0.9547731141358342\n",
      "0.9763097655587418\n",
      "0.9788738439833805\n",
      "0.9804500437074011\n",
      "0.978392153571338\n",
      "0.9179011562033808\n",
      "0.9657600364089297\n",
      "0.9804094959256703\n",
      "0.9777038987902205\n",
      "0.9535047085651042\n",
      "0.977727342752433\n",
      "0.9517781997090816\n",
      "0.9511503377760103\n",
      "0.9793784167638634\n",
      "0.9569179230283614\n",
      "0.9824351121245949\n",
      "0.9747516671996497\n",
      "0.9758819744349284\n",
      "0.9758571680708958\n",
      "------->  6 <--------\n",
      "0.963799174462788\n",
      "0.9700363677419559\n",
      "0.8224362915898067\n",
      "0.8916140949565746\n",
      "0.9782567298606142\n",
      "0.9778202755035474\n",
      "0.9788518905964056\n",
      "0.9802652507597205\n",
      "0.9788077455075916\n",
      "0.9725476550204408\n",
      "0.9793784167638634\n",
      "0.9740879434660541\n",
      "0.9601999122947453\n",
      "0.9782795046776727\n",
      "0.9380708805261235\n",
      "0.9406203331030741\n",
      "0.9798204041652855\n",
      "0.9792921236767755\n",
      "0.9762605042016806\n",
      "0.9793784167638634\n",
      "0.9377166323540626\n",
      "0.9803481232797991\n",
      "0.9525210084033613\n",
      "0.9539973012237966\n",
      "0.9813236562230525\n",
      "0.9455560319296081\n",
      "0.9430533401111325\n",
      "0.9527173465965537\n",
      "0.9752025112347222\n",
      "0.9545523888773317\n",
      "------->  7 <--------\n",
      "0.9621085347116914\n",
      "0.9762605042016806\n",
      "0.9730797607798083\n",
      "0.939650517067792\n",
      "0.9772689686318287\n",
      "0.9747778097962733\n",
      "0.9762851792784428\n",
      "0.9575488535373897\n",
      "0.9767644781707681\n",
      "0.9767644781707681\n",
      "0.9575042272843287\n",
      "0.9756554676596361\n",
      "0.9329702658529637\n",
      "0.9740057161420201\n",
      "0.9783248081841431\n",
      "0.9640323785008968\n",
      "0.9620684450175685\n",
      "0.9657600364089297\n",
      "0.9768127555915151\n",
      "0.9752797553656437\n",
      "0.9639939308236776\n",
      "0.9778202755035474\n",
      "0.9437184026803049\n",
      "0.9741962002192182\n",
      "0.9752025112347222\n",
      "0.9586708520578704\n",
      "0.9696304240404106\n",
      "0.9667976110632046\n",
      "0.9763097655587418\n",
      "0.9535047085651042\n",
      "------->  8 <--------\n",
      "0.9447748448450053\n",
      "0.972605134436643\n",
      "0.9170814190913731\n",
      "0.9773397757518401\n",
      "0.9550310697356215\n",
      "0.9762851792784428\n",
      "0.976334263435275\n",
      "0.975757045317831\n",
      "0.9849630945329394\n",
      "0.9616904288020346\n",
      "0.9787409267534661\n",
      "0.9792485069145029\n",
      "0.9563758174688559\n",
      "0.9568732961953301\n",
      "0.9756809998914979\n",
      "0.9762851792784428\n",
      "0.9783248081841431\n",
      "0.9741422674734199\n",
      "0.9772451953766096\n",
      "0.9783248081841431\n",
      "0.9536014377186927\n",
      "0.947792498133041\n",
      "0.9813824325808623\n",
      "0.98296061732523\n",
      "0.9704757799276438\n",
      "0.9803891121666057\n",
      "0.9747516671996497\n",
      "0.9813824325808623\n",
      "0.9470836926319824\n",
      "0.9231935441560102\n",
      "------->  9 <--------\n",
      "0.9767886604106892\n",
      "0.9777038987902205\n",
      "0.9695038289011686\n",
      "0.9782567298606142\n",
      "0.9737754444902792\n",
      "0.9640240680625953\n",
      "0.9792921236767755\n",
      "0.981909051043066\n",
      "0.977911877171245\n",
      "0.9788077455075916\n",
      "0.9788738439833805\n",
      "0.9757317883116912\n",
      "0.9239266451439561\n",
      "0.9787855530968386\n",
      "0.9607782243332116\n",
      "0.9773162584402497\n",
      "0.979904388179313\n",
      "0.9787409267534661\n",
      "0.9772689686318287\n",
      "0.9712192544500762\n",
      "0.9787184920983472\n",
      "0.9802860815687777\n",
      "0.9695038289011686\n",
      "0.9517391647900123\n",
      "0.9813824325808623\n",
      "0.9767644781707681\n",
      "0.9762357399332755\n",
      "0.979883505689264\n",
      "0.9844363801858771\n",
      "0.9614875992015814\n",
      "------->  10 <--------\n",
      "0.9787409267534661\n",
      "0.9778662412497907\n",
      "0.9773397757518401\n",
      "0.9788738439833805\n",
      "0.9720736488712935\n",
      "0.9773162584402497\n",
      "0.9731640482279869\n",
      "0.9584091458272324\n",
      "0.9803686547274884\n",
      "0.9783248081841431\n",
      "0.9768127555915151\n",
      "0.9699735793313244\n",
      "0.9340792316217097\n",
      "0.9783248081841431\n",
      "0.9528152276723271\n",
      "0.9510267492021747\n",
      "0.9787855530968386\n",
      "0.9828346700957165\n",
      "0.9706294904159192\n",
      "0.9752283522104495\n",
      "0.9757064399721174\n",
      "0.977221336044453\n",
      "0.9584091458272324\n",
      "0.977221336044453\n",
      "0.9705989698535397\n",
      "0.9792265797470743\n",
      "0.9757822113955824\n",
      "0.9549582336834079\n",
      "0.9643721998618444\n",
      "0.9616097377918305\n",
      "------->  11 <--------\n",
      "0.9747516671996497\n",
      "0.95148885641213\n",
      "0.950813312010901\n",
      "0.9736938151321144\n",
      "0.9777507020283916\n",
      "0.9793354260289351\n",
      "0.9736389029484678\n",
      "0.9782338725114854\n",
      "0.9691316479590544\n",
      "0.9788957184009632\n",
      "0.9802023028689641\n",
      "0.9611114513782915\n",
      "0.9797779547167116\n",
      "0.9824167418819256\n",
      "0.9647966102505183\n",
      "0.9633344619378139\n",
      "0.9757064399721174\n",
      "0.9571413287599828\n",
      "0.9616501563297601\n",
      "0.9808149826799571\n",
      "0.977386557067917\n",
      "0.9763097655587418\n",
      "0.9103829427361383\n",
      "0.937941441936208\n",
      "0.9656875453074667\n",
      "0.9553371464562095\n",
      "0.9768367640986183\n",
      "0.9752283522104495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7775177982907934\n",
      "0.9778202755035474\n",
      "------->  12 <--------\n",
      "0.9395245420582494\n",
      "0.9809151207821223\n",
      "0.9793354260289351\n",
      "0.9762851792784428\n",
      "0.9788518905964056\n",
      "0.9762605042016806\n",
      "0.9752797553656437\n",
      "0.9521293124704779\n",
      "0.9838578446899824\n",
      "0.9731079581723567\n",
      "0.9787184920983472\n",
      "0.9793997961380365\n",
      "0.968905532159265\n",
      "0.979883505689264\n",
      "0.9044422668365413\n",
      "0.9640323785008968\n",
      "0.9758072869474457\n",
      "0.9809151207821223\n",
      "0.9778432997874478\n",
      "0.9767886604106892\n",
      "0.9792921236767755\n",
      "0.975906691858003\n",
      "0.962385136848458\n",
      "0.9610206417492206\n",
      "0.9777971680298451\n",
      "0.9240966911346989\n",
      "0.9765927319487043\n",
      "0.9814018834260416\n",
      "0.9461595215596161\n",
      "0.9788298578889221\n",
      "------->  13 <--------\n",
      "0.9773397757518401\n",
      "0.9767644781707681\n",
      "0.9621484793415371\n",
      "0.9761859422282918\n",
      "0.9549367167316669\n",
      "0.9291868569400015\n",
      "0.9680696840139564\n",
      "0.9675041245749648\n",
      "0.9793138139787361\n",
      "0.977727342752433\n",
      "0.9464233642381454\n",
      "0.9762108860755463\n",
      "0.9783248081841431\n",
      "0.9803686547274884\n",
      "0.9705375974129933\n",
      "0.975757045317831\n",
      "0.976334263435275\n",
      "0.9376349133660846\n",
      "0.9590373954518004\n",
      "0.9752797553656437\n",
      "0.9543947805002553\n",
      "0.9374919173471866\n",
      "0.9745928149004839\n",
      "0.9569633395253094\n",
      "0.979862547747999\n",
      "0.9640323785008968\n",
      "0.976666870826975\n",
      "0.9797566144350132\n",
      "0.9522715659033567\n",
      "0.9762357399332755\n",
      "------->  14 <--------\n",
      "0.9776803697616812\n",
      "0.9773397757518401\n",
      "0.8721958930468082\n",
      "0.980895237607076\n",
      "0.9590373954518004\n",
      "0.9772689686318287\n",
      "0.9460461179777075\n",
      "0.964979653434662\n",
      "0.9789175141980675\n",
      "0.9608189918513405\n",
      "0.9667273166617858\n",
      "0.9748298135207211\n",
      "0.9808752825312412\n",
      "0.9781879087344278\n",
      "0.9792921236767755\n",
      "0.974646148823051\n",
      "0.9752797553656437\n",
      "0.9633395100027675\n",
      "0.9679364116670408\n",
      "0.96368488710038\n",
      "0.979883505689264\n",
      "0.9752283522104495\n",
      "0.9740879434660541\n",
      "0.9569179230283614\n",
      "0.9523218159775395\n",
      "0.976740208483942\n",
      "0.9583649721098179\n",
      "0.9813824325808623\n",
      "0.9477400210434317\n",
      "0.9689381855151632\n",
      "------->  15 <--------\n",
      "0.9555971615468183\n",
      "0.9773397757518401\n",
      "0.9558464699142666\n",
      "0.9788298578889221\n",
      "0.9675041245749648\n",
      "0.9752797553656437\n",
      "0.9761105667091354\n",
      "0.9773632085033066\n",
      "0.9761609079887699\n",
      "0.9777971680298451\n",
      "0.975757045317831\n",
      "0.9798204041652855\n",
      "0.9797992178452299\n",
      "0.9792265797470743\n",
      "0.8498236421499823\n",
      "0.9777507020283916\n",
      "0.9762851792784428\n",
      "0.9762851792784428\n",
      "0.9782795046776727\n",
      "0.9778432997874478\n",
      "0.9788738439833805\n",
      "0.9747254302249727\n",
      "0.9704757799276438\n",
      "0.9564545623927473\n",
      "0.9624628911331448\n",
      "0.975254100116636\n",
      "0.9727470305487216\n",
      "0.9480564216149618\n",
      "0.9762108860755463\n",
      "0.979904388179313\n",
      "------->  16 <--------\n",
      "0.9613545926525253\n",
      "0.9782795046776727\n",
      "0.9782795046776727\n",
      "0.9814018834260416\n",
      "0.9731919417930225\n",
      "0.9566946752041132\n",
      "0.9436596161055486\n",
      "0.9555494521525059\n",
      "0.979883505689264\n",
      "0.9724897580783514\n",
      "0.9793997961380365\n",
      "0.9574144884815021\n",
      "0.9597040807564235\n",
      "0.9746726714602927\n",
      "0.9578669175076678\n",
      "0.9362712062823118\n",
      "0.9566883515705107\n",
      "0.9766914052060345\n",
      "0.9633395100027675\n",
      "0.9569633395253094\n",
      "0.978302197330382\n",
      "0.9717186166071639\n",
      "0.9793997961380365\n",
      "0.9454409140663658\n",
      "0.9793354260289351\n",
      "0.9667625275953187\n",
      "0.979904388179313\n",
      "0.9516395818025185\n",
      "0.9583649721098179\n",
      "0.9788077455075916\n",
      "------->  17 <--------\n",
      "0.9803068370342011\n",
      "0.9778202755035474\n",
      "0.9804298063311345\n",
      "0.9351173539583757\n",
      "0.9735835925668392\n",
      "0.9788957184009632\n",
      "0.9758072869474457\n",
      "0.9515895209243856\n",
      "0.9777038987902205\n",
      "0.9444604549883695\n",
      "0.9476300878560993\n",
      "0.9557862714586638\n",
      "0.9726905788077844\n",
      "0.9793138139787361\n",
      "0.9458402076249415\n",
      "0.9297035171983106\n",
      "0.963799174462788\n",
      "0.955501568417887\n",
      "0.9777971680298451\n",
      "0.9777739769957668\n",
      "0.9766422474250152\n",
      "0.978302197330382\n",
      "0.9753307895286367\n",
      "0.9715117174740423\n",
      "0.9803891121666057\n",
      "0.9797779547167116\n",
      "0.9741962002192182\n",
      "0.9611930849332413\n",
      "0.9470366820097798\n",
      "0.9501964165948069\n",
      "------->  18 <--------\n",
      "0.9281530884281768\n",
      "0.9378450497144337\n",
      "0.9579115622797678\n",
      "0.9419544679151324\n",
      "0.9771250302049778\n",
      "0.9758072869474457\n",
      "0.9590804669172607\n",
      "0.9773632085033066\n",
      "0.9022887135077893\n",
      "0.9592512038320988\n",
      "0.9399255715045188\n",
      "0.9763097655587418\n",
      "0.9589507829642181\n",
      "0.9778432997874478\n",
      "0.9778202755035474\n",
      "0.9776330549732064\n",
      "0.9605721631375554\n",
      "0.9079116900519244\n",
      "0.9834162838182747\n",
      "0.9763097655587418\n",
      "0.9788077455075916\n",
      "0.9788298578889221\n",
      "0.9818520106432027\n",
      "0.8863719077013243\n",
      "0.9788738439833805\n",
      "0.9572786535593438\n",
      "0.9623068201436906\n",
      "0.9737211230037172\n",
      "0.9782795046776727\n",
      "0.9673679672884484\n",
      "------->  19 <--------\n",
      "The best solution is :  [1 1 1 1 0 1 0 0 1 0 0]  in n_iteration:  20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = wine()\n",
    "x_train,x_test,y_train, y_test = train_test_split(X , y , test_size=0.4 , random_state=0)\n",
    "\n",
    "c1 = 0.8\n",
    "c2 = 0.9\n",
    "target_error = 0.00006\n",
    "n_particles = 30\n",
    "W = 0.5\n",
    "iteration = 0 \n",
    "n_iterations = 20\n",
    "\n",
    "# get accuracy with all features\n",
    "all_particle = [1 for i in range(len(x_train.columns))] # true column (feature)\n",
    "all_fitness = fitness_function(np.asarray(all_particle), x_train, y_train, x_test, y_test)\n",
    "print(\"All feature error : \", all_fitness)\n",
    "\n",
    "particle_position = [np.random.randint(1, size=len(x_train.columns)) for _ in range(n_particles)]\n",
    "pbest_position = particle_position\n",
    "pbest_fitness_value = np.array([float('inf') for _ in range(n_particles)])\n",
    "gbest_fitness_value = float('inf')\n",
    "gbest_position = np.array([float('inf'), float('inf'), float('inf'), float('inf')])\n",
    "velocity_vector = ([np.zeros(len(x_train.columns)) for _ in range(n_particles)])\n",
    "\n",
    "\n",
    "while(iteration < n_iterations):\n",
    "    for i in range(n_particles):\n",
    "        \n",
    "        fitness_cadidate = fitness_function(particle_position[i], x_train, y_train, x_test, y_test)\n",
    "        # print(fitness_cadidate)\n",
    "        if(pbest_fitness_value[i] > fitness_cadidate):\n",
    "            pbest_fitness_value[i] = fitness_cadidate\n",
    "            pbest_position[i] = particle_position[i]\n",
    "        \n",
    "        if(gbest_fitness_value > fitness_cadidate):\n",
    "            print(\"update from :\", gbest_fitness_value, \" to \", fitness_cadidate)\n",
    "            print(particle_position[i])\n",
    "            gbest_fitness_value = fitness_cadidate\n",
    "            gbest_position = particle_position[i]\n",
    "            \n",
    "        if(gbest_fitness_value == fitness_cadidate):\n",
    "            print(\"Don't change!!!\")\n",
    "            \n",
    "    for i in range(n_particles):\n",
    "        # velocity\n",
    "        new_velocity = (W*velocity_vector[i]) + (c1*random.random()) * (pbest_position[i] - particle_position[i]) + (c2*random.random()) * (gbest_position-particle_position[i])\n",
    "        # position\n",
    "        new_position = new_velocity + particle_position[i]\n",
    "        # sigmoid\n",
    "        new_position = [0 if np.random.uniform(0, 1)>= sigmoid_function(x) else 1 for x in new_position]\n",
    "        particle_position[i] = np.asarray(new_position)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"-------> \", iteration, \"<--------\")\n",
    "    iteration += 1\n",
    "\n",
    "print(\"The best solution is : \", gbest_position, \" in n_iteration: \", iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # search_space = Space(1, target_error, n_particles)\n",
    "# # particle_vector = [Particle() for _ in range(search_space.n_particles)]\n",
    "# # search_space.particle = particle_vector\n",
    "# def fitness_function(position):\n",
    "#     return position[0]**2 + position[1]**2 + 1\n",
    "\n",
    "# particle_position_vector = np.array([np.array([(-1) ** (bool(random.getrandbits(1))) * random.random()*50, (-1)**(bool(random.getrandbits(1))) * random.random()*50]) for _ in range(n_particles)])\n",
    "# print(type(particle_position_vector))\n",
    "# pbest_position = particle_position_vector\n",
    "# pbest_fitness_value = np.array([float('inf') for _ in range(n_particles)])\n",
    "\n",
    "# gbest_fitness_value = float('inf')\n",
    "# gbest_position = np.array([float('inf'), float('inf')])\n",
    "\n",
    "# velocity_vector = ([np.array([0, 0]) for _ in range(n_particles)])\n",
    "# target = 1\n",
    "# W = 0.5\n",
    "\n",
    "\n",
    "# iteration = 0\n",
    "# while(iteration < n_iterations):\n",
    "#     for i in range(n_particles):\n",
    "#         # search_space.set_pbest()\n",
    "#         fitness_cadidate = fitness_function(particle_position_vector[i])\n",
    "    \n",
    "#         # search_space.set_gbest()\n",
    "        \n",
    "#         if(pbest_fitness_value[i] > fitness_cadidate):\n",
    "#             pbest_fitness_value[i] = fitness_cadidate\n",
    "#             pbest_position[i] = particle_position_vector[i]\n",
    "        \n",
    "#         if(gbest_fitness_value > fitness_cadidate):\n",
    "#             gbest_fitness_value = fitness_cadidate\n",
    "#             gbest_position = particle_position_vector[i]\n",
    "    \n",
    "\n",
    "#     if(abs(gbest_fitness_value - target) < target_error):\n",
    "#         break\n",
    "        \n",
    "#     # search_space.move_particles()\n",
    "#     for i in range(n_particles):\n",
    "#         new_velocity = (W*velocity_vector[i]) + (c1*random.random()) * (pbest_position[i] - particle_position_vector[i]) + (c2*random.random()) * (gbest_position-particle_position_vector[i])\n",
    "                \n",
    "#         new_position = new_velocity + particle_position_vector[i]\n",
    "#         particle_position_vector[i] = new_position\n",
    "    \n",
    "#     print(\"-------> \", iteration, \"<--------\")\n",
    "#     iteration += 1\n",
    "\n",
    "# print(\"The best solution is : \", gbest_position, \" in n_iteration: \", iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
